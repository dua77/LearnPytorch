{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Pytorch\n",
    "References:\n",
    "* https://towardsdatascience.com/pytorch-tutorial-distilled-95ce8781a89c\n",
    "* http://adventuresinmachinelearning.com/pytorch-tutorial-deep-learning/\n",
    "* https://hsaghir.github.io/data_science/pytorch_starter/\n",
    "* https://jdhao.github.io/2017/11/12/pytorch-computation-graph/\n",
    "* https://discuss.pytorch.org/t/print-autograd-graph/692/4\n",
    "* https://medium.com/intuitionmachine/pytorch-dynamic-computational-graphs-and-modular-deep-learning-7e7f89f18d1\n",
    "* https://medium.com/init27-labs/pytorch-basics-in-4-minutes-c7814fa5f03d\n",
    "* https://github.com/PaddlePaddle/VisualDL\n",
    "* https://www.youtube.com/watch?v=rrekAv9Fml4\n",
    "* https://www.youtube.com/watch?v=LAMwEJZqesU\n",
    "* https://github.com/lanpa/tensorboard-pytorch\n",
    "* https://github.com/lanpa/tensorboard-pytorch-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch libraries\n",
    "import torch\n",
    "# Neural network support\n",
    "import torch.nn as nn\n",
    "# Optimizer (SGD, Adam, Etc...)\n",
    "import torch.optim as optim\n",
    "\n",
    "# Library that gives support for tensorboard and pytorch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# Set enviroment variable for make only the first GPU visible\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tensors\n",
    "You can consider pytorch as a linear algebra library (like numpy) with support for calculations on the GPU and Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x2 tensor:\n",
      "tensor([ 1,  2])\n",
      "torch.Size([2])\n",
      "\n",
      "2x2 tensor:\n",
      "tensor([[ 1,  2],\n",
      "        [ 3,  4]])\n",
      "torch.Size([2, 2])\n",
      "All rows from first collumn\n",
      "tensor([ 1,  3])\n",
      "torch.Size([2])\n",
      "\n",
      "Non-initialized 5x3 tensor:\n",
      "tensor([[ 1.3988e+14,  1.3988e+14,  1.0000e+00],\n",
      "        [ 5.6592e+07,  1.0000e+00,  4.2950e+09],\n",
      "        [ 6.4000e+01,  6.4000e+01,  5.6598e+07],\n",
      "        [ 2.0000e+00,  3.0065e+10,  1.3988e+14],\n",
      "        [ 0.0000e+00,  1.3964e+14,  1.2800e+02]])\n",
      "\n",
      "Random 5x3 tensor:\n",
      "tensor([[ 0.6224,  0.9536,  0.8155],\n",
      "        [ 0.1915,  0.9667,  0.6261],\n",
      "        [ 0.8117,  0.1787,  0.2665],\n",
      "        [ 0.1328,  0.7333,  0.2689],\n",
      "        [ 0.5241,  0.0260,  0.2483]])\n",
      "\n",
      "Zeros 5x3 tensor:\n",
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0]])\n",
      "\n",
      "Zeros 5x3 tensor:\n",
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "\n",
      "Zeros 5x3 tensor:\n",
      "tensor([[ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix 2x2\n",
    "x = torch.tensor([1, 2])\n",
    "print('1x2 tensor:')\n",
    "print(x)\n",
    "print(x.size())\n",
    "\n",
    "# Create a matrix 2x2\n",
    "x = torch.tensor([[1, 2],[3, 4]])\n",
    "print('\\n2x2 tensor:')\n",
    "print(x)\n",
    "print(x.size())\n",
    "print('All rows from first collumn')\n",
    "# We can have all numpy cool matrix sub-indexing\n",
    "print(x[:, 0])\n",
    "print(x[:, 0].size())\n",
    "\n",
    "## Create unitialized 5x3 tensor\n",
    "x = torch.empty(5, 3, dtype=torch.long)\n",
    "print('\\nNon-initialized 5x3 tensor:')\n",
    "print(x)\n",
    "\n",
    "# Create random 5x3 tensor\n",
    "x = torch.rand(5, 3)\n",
    "print('\\nRandom 5x3 tensor:')\n",
    "print(x)\n",
    "\n",
    "# Create 5x3 zeros tensor of type \n",
    "print('\\nZeros 5x3 tensor:')\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)\n",
    "\n",
    "# Create 5x3 zeros tensor of type \n",
    "print('\\nZeros 5x3 tensor:')\n",
    "x = torch.ones(5, 3, dtype=torch.double)\n",
    "print(x)\n",
    "\n",
    "# Create 5x3 zeros tensor of type \n",
    "print('\\nZeros 5x3 tensor:')\n",
    "y= torch.ones(5, 3, dtype=torch.double) * 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "Pytorch implement most of the numpy operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  3.,  3.],\n",
      "        [ 3.,  3.,  3.],\n",
      "        [ 3.,  3.,  3.],\n",
      "        [ 3.,  3.,  3.],\n",
      "        [ 3.,  3.,  3.]], dtype=torch.float64)\n",
      "tensor([[ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.]], dtype=torch.float64)\n",
      "tensor([[ 3.5000,  3.5000,  3.5000],\n",
      "        [ 3.5000,  3.5000,  3.5000],\n",
      "        [ 3.5000,  3.5000,  3.5000],\n",
      "        [ 3.5000,  3.5000,  3.5000],\n",
      "        [ 3.5000,  3.5000,  3.5000]], dtype=torch.float64)\n",
      "tensor([ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000,\n",
      "         3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000,\n",
      "         3.5000], dtype=torch.float64)\n",
      "torch.Size([15])\n",
      "tensor([[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n",
      "        [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n",
      "        [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000]], dtype=torch.float64)\n",
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "print(x+y)\n",
    "print(x*y)\n",
    "print((x+6)/y)\n",
    "\n",
    "# Reshape\n",
    "print(((x+6)/y).view(15))\n",
    "print(((x+6)/y).view(15).size())\n",
    "print(((x+6)/y).view(3,5))\n",
    "print(((x+6)/y).view(3,5).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Bridge\n",
    "Allows converting tensors from pytorch to numpy and from numpy to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]]\n",
      "(5, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([[ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Convert torch tensor to numpy\n",
    "y_numpy = y.numpy()\n",
    "print(y_numpy)\n",
    "print(y_numpy.shape)\n",
    "print(type(y_numpy))\n",
    "\n",
    "# Convert numpy ndarray to torch\n",
    "y_torch = torch.from_numpy(y_numpy)\n",
    "print(y_torch)\n",
    "print(y_torch.size())\n",
    "print(type(y_torch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with GPU\n",
    "Send data and do calculations on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[-1.5000, -1.5000, -1.5000],\n",
      "        [-1.5000, -1.5000, -1.5000],\n",
      "        [-1.5000, -1.5000, -1.5000],\n",
      "        [-1.5000, -1.5000, -1.5000],\n",
      "        [-1.5000, -1.5000, -1.5000]], dtype=torch.float64, device='cuda:0')\n",
      "tensor([[-1.5000, -1.5000, -1.5000],\n",
      "        [-1.5000, -1.5000, -1.5000],\n",
      "        [-1.5000, -1.5000, -1.5000],\n",
      "        [-1.5000, -1.5000, -1.5000],\n",
      "        [-1.5000, -1.5000, -1.5000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    # Point to your GPU\n",
    "    device = torch.device(\"cuda:0\") \n",
    "    # Move tensor on GPU\n",
    "    x_gpu = x.to(device)\n",
    "    y_gpu = y.to(device)\n",
    "    # Create tensor on GPU\n",
    "    b_gpu = torch.ones_like(x, device=device) + 3.5\n",
    "    # Result and the calculation will be on the GPU\n",
    "    result = x_gpu + y_gpu - b_gpu\n",
    "    print(result)\n",
    "    # Move to CPU\n",
    "    result_cpu = result.to(\"cpu\", torch.double)\n",
    "    print(result_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd\n",
    "Automatically calculate the effect of a function parameter into the output (Chain-Rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 10.])\n",
      "<AddBackward1 object at 0x7f3744f89be0>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(1, requires_grad=True)\n",
    "b = torch.ones(1, requires_grad=True)\n",
    "c = torch.ones(1, requires_grad=True)\n",
    "y = ((2*a) * (3*b)) + (4*c)\n",
    "print(y)\n",
    "y.backward()\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.])\n",
      "tensor([ 6.])\n",
      "tensor([ 4.])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)\n",
    "print(b.grad)\n",
    "print(c.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple MLP for XOR problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdataX = [[[0.01, 0.01], [0.01, 0.90], [0.90, 0.01], [0.95, 0.95]], \n",
    "                 [[0.02, 0.03], [0.04, 0.95], [0.97, 0.02], [0.96, 0.95]]]\n",
    "trainingdataY = [[[0.01], [0.90], [0.90], [0.01]], [[0.04], [0.97], [0.98], [0.1]]]\n",
    "num_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    # Add layers\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 50)  # 2 Input noses, 50 in middle layers\n",
    "        self.fc2 = nn.Linear(50, 1)  # 50 middle layer, 1 output nodes\n",
    "        self.rl1 = nn.ReLU()\n",
    "        self.rl2 = nn.ReLU()\n",
    "\n",
    "    # Define Forward propagation graph\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.rl1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.rl2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (rl1): ReLU()\n",
      "  (rl2): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard writer at logs directory\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "# Create network\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "# Send graph to tensorboard\n",
    "writer.add_graph(net, torch.rand(4,2))\n",
    "\n",
    "# Loss (Mean squared error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Stochastic Gradient Descent Optimizer \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0 0.3227727711200714\n",
      "loss:  0 0.2476765513420105\n",
      "loss:  0 0.20148196816444397\n",
      "loss:  0 0.18929597735404968\n",
      "loss:  0 0.1779015213251114\n",
      "loss:  0 0.16722047328948975\n",
      "loss:  0 0.15708935260772705\n",
      "loss:  0 0.14734986424446106\n",
      "loss:  0 0.13827751576900482\n",
      "loss:  0 0.1294705867767334\n",
      "loss:  0 0.12094464898109436\n",
      "loss:  0 0.11289694160223007\n",
      "loss:  0 0.10484233498573303\n",
      "loss:  0 0.09720581769943237\n",
      "loss:  0 0.0893995612859726\n",
      "loss:  0 0.08209510892629623\n",
      "loss:  0 0.07511371374130249\n",
      "loss:  0 0.0688881054520607\n",
      "loss:  0 0.0630224198102951\n",
      "loss:  0 0.057847000658512115\n",
      "loss:  0 0.053466688841581345\n",
      "loss:  0 0.049107626080513\n",
      "loss:  0 0.04515097290277481\n",
      "loss:  0 0.041556261479854584\n",
      "loss:  0 0.03707286715507507\n",
      "loss:  0 0.03449761122465134\n",
      "loss:  0 0.03173501417040825\n",
      "loss:  0 0.028862591832876205\n",
      "loss:  0 0.026337821036577225\n",
      "loss:  0 0.02375251241028309\n",
      "loss:  0 0.02213069424033165\n",
      "loss:  0 0.020114663988351822\n",
      "loss:  0 0.0180179625749588\n",
      "loss:  0 0.01695568859577179\n",
      "loss:  0 0.01517345942556858\n",
      "loss:  0 0.013728110119700432\n",
      "loss:  0 0.012889523059129715\n",
      "loss:  0 0.011843428015708923\n",
      "loss:  0 0.010905676521360874\n",
      "loss:  0 0.010077673941850662\n",
      "loss:  0 0.009790022857487202\n",
      "loss:  0 0.008499779738485813\n",
      "loss:  0 0.00846964679658413\n",
      "loss:  0 0.007593963295221329\n",
      "loss:  0 0.007069772109389305\n",
      "loss:  0 0.007123005110770464\n",
      "loss:  0 0.0063340854831039906\n",
      "loss:  0 0.006014345213770866\n",
      "loss:  0 0.005809344816952944\n",
      "loss:  0 0.005747706163674593\n",
      "loss:  0 0.005336998961865902\n",
      "loss:  0 0.005087589845061302\n",
      "loss:  0 0.0050272224470973015\n",
      "loss:  0 0.005039434880018234\n",
      "loss:  0 0.004501086659729481\n",
      "loss:  0 0.004712108056992292\n",
      "loss:  0 0.004363593645393848\n",
      "loss:  0 0.004298890009522438\n",
      "loss:  0 0.004440330900251865\n",
      "loss:  0 0.004100295715034008\n",
      "loss:  0 0.003937762696295977\n",
      "loss:  0 0.0041650268249213696\n",
      "loss:  0 0.00384578388184309\n",
      "loss:  0 0.0037302635610103607\n",
      "loss:  0 0.004051591735333204\n",
      "loss:  0 0.00369062228128314\n",
      "loss:  0 0.003553852206096053\n",
      "loss:  0 0.003638536436483264\n",
      "loss:  0 0.0037616840563714504\n",
      "loss:  0 0.0034825140610337257\n",
      "loss:  0 0.0033968170173466206\n",
      "loss:  0 0.00342714786529541\n",
      "loss:  0 0.0033803365658968687\n",
      "loss:  0 0.003461888525635004\n",
      "loss:  0 0.00347874965518713\n",
      "loss:  0 0.003422267036512494\n",
      "loss:  0 0.0033076340332627296\n",
      "loss:  0 0.0032343610655516386\n",
      "loss:  0 0.0032515719067305326\n",
      "loss:  0 0.00331109412945807\n",
      "loss:  0 0.0033087851479649544\n",
      "loss:  0 0.003314623609185219\n",
      "loss:  0 0.003336107125505805\n",
      "loss:  0 0.0032165241427719593\n",
      "loss:  0 0.0031661936081945896\n",
      "loss:  0 0.0031629835721105337\n",
      "loss:  0 0.0031544743105769157\n",
      "loss:  0 0.003202978055924177\n",
      "loss:  0 0.003237334545701742\n",
      "loss:  0 0.0032157390378415585\n",
      "loss:  0 0.0032531614415347576\n",
      "loss:  0 0.0032035005278885365\n",
      "loss:  0 0.003112265607342124\n",
      "loss:  0 0.003071199869737029\n",
      "loss:  0 0.0030703567899763584\n",
      "loss:  0 0.0031120481435209513\n",
      "loss:  0 0.0031480086036026478\n",
      "loss:  0 0.0032354716677218676\n",
      "loss:  0 0.003164107445627451\n",
      "loss:  0 0.0030759451910853386\n"
     ]
    }
   ],
   "source": [
    "# For each epoch (epoch==>Run on the entire dataset)\n",
    "for epoch in range(num_epoch):\n",
    "    running_loss = 0.0\n",
    "    # For each element on the dataset\n",
    "    for i, data in enumerate(trainingdataX, 0):\n",
    "        # Get data\n",
    "        inputs = data\n",
    "        labels = trainingdataY[i]\n",
    "        \n",
    "        # Convert input/labels to torch tensors\n",
    "        inputs = torch.FloatTensor(inputs)\n",
    "        labels = torch.FloatTensor(labels)\n",
    "        \n",
    "        # Manually set gradients to zero before the loss.backward() and optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Propagation\n",
    "        outputs = net(inputs)\n",
    "                \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Compute loss backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Run optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get loss scalar value\n",
    "        running_loss += loss.item()                \n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"loss: \", i, running_loss)\n",
    "            # Send loss to tensorboard\n",
    "            writer.add_scalar('loss', running_loss, epoch)\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Close summary writer\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
